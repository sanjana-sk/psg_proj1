{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "txd-U9I2eDFU"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150,150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AVA22f-eIIT"
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(20, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGRD5hD3eL4I",
        "outputId": "6c445d63-0263-4586-be5d-837989f519c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 34, 34, 64)        36928     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 73984)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                4735040   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20)                1300      \n",
            "=================================================================\n",
            "Total params: 4,792,660\n",
            "Trainable params: 4,792,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOy1Rs8yeaUj"
      },
      "source": [
        "from keras import optimizers\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg9cjgYRedVP",
        "outputId": "e9fe2bfb-7987-4e55-9f5a-c156e8cb556f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Accessing dataset from google drive\n",
        "from google.colab import drive \n",
        "drive.mount('/mntDrive')\n",
        "dataPath='/mntDrive/My Drive/cas_peal/'\n",
        "train_dir = dataPath+'train'\n",
        "val_dir = dataPath+'test'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /mntDrive; to attempt to forcibly remount, call drive.mount(\"/mntDrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thThrjyreqD-",
        "outputId": "a4746aa4-5255-492d-96af-40fcd041ce98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                # This is the target directory\n",
        "                train_dir,\n",
        "                # All images will be resized to 150x150\n",
        "                target_size=(150, 150),\n",
        "                batch_size=20,\n",
        "                # Since we use binary_crossentropy loss, we need binary labels\n",
        "              class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "                val_dir,\n",
        "                target_size=(150, 150),\n",
        "                batch_size=20,\n",
        "                class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 639 images belonging to 20 classes.\n",
            "Found 60 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n4VtXZWEd4-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHbR9JhjewSY",
        "outputId": "3c1d72bb-8568-4764-cb46-d031dda37199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for data_batch, labels_batch in validation_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data batch shape: (20, 150, 150, 3)\n",
            "labels batch shape: (20, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvpF_d6GfCVm",
        "outputId": "0c206e7f-777d-4f6f-97e6-36237a759645",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "train_generator,\n",
        "epochs=5,\n",
        "validation_data=validation_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 26s 803ms/step - loss: 2.7905 - acc: 0.1408 - val_loss: 2.4727 - val_acc: 0.3500\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 26s 815ms/step - loss: 2.4040 - acc: 0.2848 - val_loss: 1.9439 - val_acc: 0.2667\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 25s 793ms/step - loss: 1.9948 - acc: 0.4210 - val_loss: 1.4705 - val_acc: 0.6833\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 26s 799ms/step - loss: 1.5893 - acc: 0.5900 - val_loss: 1.1235 - val_acc: 0.7000\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 25s 784ms/step - loss: 1.2749 - acc: 0.6870 - val_loss: 0.7353 - val_acc: 0.8167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6zgtVPKPpvh"
      },
      "source": [
        "model.save('20_face.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UOZR40QGe_z",
        "outputId": "be83b1e2-53dd-414a-dc9f-4ed2f07e7c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "final_test_dir=dataPath + 'final_test'\n",
        "\n",
        "final_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "final_test_datagenerator = final_test_datagen.flow_from_directory(\n",
        "                # This is the target directory\n",
        "                final_test_dir,\n",
        "                # All images will be resized to 150x150\n",
        "                target_size=(150, 150),\n",
        "                batch_size=20,\n",
        "                # Since we use binary_crossentropy loss, we need binary labels\n",
        "              class_mode='categorical')\n",
        "filenames = final_test_datagenerator.filenames\n",
        "nb_samples = len(filenames)\n",
        "print(nb_samples)\n",
        "predict = model.predict_generator(final_test_datagenerator,steps = \n",
        "                                   np.ceil(nb_samples/1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2 images belonging to 2 classes.\n",
            "2\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2.0 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RfDNxRdKQzl",
        "outputId": "899de196-ecd4-4b89-fc06-2312ff010d3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.4251390e-03, 1.3872809e-04, 1.4956680e-03, 1.5557070e-03,\n",
              "        5.8800417e-01, 5.4315902e-02, 1.4877420e-04, 1.3551653e-03,\n",
              "        6.5266876e-04, 1.4248936e-02, 3.4905302e-03, 3.6080644e-02,\n",
              "        4.1364476e-02, 2.7957469e-02, 1.6801003e-02, 2.1198392e-03,\n",
              "        1.3667765e-01, 1.7388819e-02, 4.2575601e-02, 1.2203002e-02],\n",
              "       [8.2428384e-01, 1.0457250e-03, 3.5043102e-04, 3.5161457e-03,\n",
              "        5.4952176e-04, 1.3525940e-02, 2.7962960e-02, 1.4275186e-04,\n",
              "        7.4942823e-04, 2.2633674e-05, 7.2746530e-05, 6.8875104e-02,\n",
              "        4.5216587e-04, 3.3945526e-05, 2.3687878e-03, 5.1608566e-02,\n",
              "        4.1158395e-03, 1.1152504e-06, 3.0540879e-04, 1.6949705e-05]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    }
  ]
}